{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ed821329-bb07-4fe5-934a-6eae515f644f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a047a623-4e85-4e83-abd6-fdd10f7b449b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the Excel files\n",
    "fatality_file = 'bitre_fatalities_dec2024.xlsx'\n",
    "crash_file = 'bitre_fatal_crashes_dec2024.xlsx'\n",
    "\n",
    "# Read specific sheets\n",
    "df_fatality = pd.read_excel(fatality_file, sheet_name='BITRE_Fatality', skiprows=4)\n",
    "df_crash = pd.read_excel(crash_file, sheet_name='BITRE_Fatal_Crash', skiprows=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c10a2f8f-134b-48f3-9b25-743943847865",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fatality columns: ['Crash ID', 'State', 'Month', 'Year', 'Dayweek', 'Time', 'Crash Type', 'Bus Involvement', 'Heavy Rigid Truck Involvement', 'Articulated Truck Involvement', 'Speed Limit', 'Road User', 'Gender', 'Age', 'National Remoteness Areas', 'SA4 Name 2021', 'National LGA Name 2021', 'National Road Type', 'Christmas Period', 'Easter Period', 'Age Group', 'Day of week', 'Time of day']\n",
      "Crash columns: ['Crash ID', 'State', 'Month', 'Year', 'Dayweek', 'Time', 'Crash Type', 'Number Fatalities', 'Bus \\nInvolvement', 'Heavy Rigid Truck Involvement', 'Articulated Truck Involvement', 'Speed Limit', 'National Remoteness Areas', 'SA4 Name 2021', 'National LGA Name 2021', 'National Road Type', 'Christmas Period', 'Easter Period', 'Day of week', 'Time of Day']\n"
     ]
    }
   ],
   "source": [
    "print(\"Fatality columns:\", df_fatality.columns.tolist())\n",
    "print(\"Crash columns:\", df_crash.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ef15328b-f784-43bf-aa5b-d94b06c95784",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean column names (remove extra spaces if any)\n",
    "df_fatality.columns = df_fatality.columns.str.strip()\n",
    "df_crash.columns = df_crash.columns.str.strip()\n",
    "\n",
    "# Perform LEFT JOIN on 'Crash ID'\n",
    "merged_df = pd.merge(\n",
    "    df_fatality,\n",
    "    df_crash,\n",
    "    on='Crash ID',\n",
    "    how='left',\n",
    "    suffixes=('_fatality', '_crash')\n",
    ")\n",
    "\n",
    "# Drop all columns that end with '_crash'\n",
    "merged_df = merged_df.loc[:, ~merged_df.columns.str.endswith('_crash')]\n",
    "# Rename columns by removing '_fatality' suffix\n",
    "merged_df.columns = merged_df.columns.str.replace('_fatality$', '', regex=True)\n",
    "# Remove truly duplicated columns (identical values)\n",
    "merged_df = merged_df.loc[:, ~merged_df.T.duplicated()]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9025f72e-bd8d-475a-b9c6-21140c5b1aed",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Aparna\\AppData\\Local\\Temp\\ipykernel_21272\\2641093565.py:7: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  merged_df[speed_col] = merged_df[speed_col].replace('<40', 40)\n"
     ]
    }
   ],
   "source": [
    "# Column Groups \n",
    "involvement_cols = ['Bus Involvement','Heavy Rigid Truck Involvement','Articulated Truck Involvement']\n",
    "categorical_cols = ['National Remoteness Areas', 'SA4 Name 2021', 'National LGA Name 2021','National Road Type']\n",
    "speed_col = 'Speed Limit'\n",
    "\n",
    "# Clean Speed Limit \n",
    "merged_df[speed_col] = merged_df[speed_col].replace('<40', 40)\n",
    "# First convert -9 to NaN\n",
    "merged_df[speed_col] = merged_df[speed_col].replace(-9, np.nan)\n",
    "# Then ensure the column is of nullable integer type\n",
    "merged_df[speed_col] = pd.to_numeric(merged_df[speed_col], errors='coerce').astype('Int64')\n",
    "\n",
    "# Clean Involvement Flags\n",
    "for col in involvement_cols:\n",
    "    merged_df[col] = merged_df[col].astype(str).apply(\n",
    "        lambda x: 'Unknown' if str(x).strip().lower() in ['', 'unknown', '-9', 'nan'] else x\n",
    "    )\n",
    "\n",
    "# Clean All Categorical Columns\n",
    "for col in categorical_cols:\n",
    "    merged_df[col] = merged_df[col].astype(str).apply(\n",
    "        lambda x: 'Unknown' if str(x).strip().lower() in ['', 'unknown', '-9', 'nan'] else x\n",
    "    )\n",
    "\n",
    "# Special: Crash Type Rule\n",
    "def fix_single_crash_vehicle_flags(row):\n",
    "    if str(row['Crash Type']).strip().lower() == 'single':\n",
    "        yes_count = sum([row[col] == 'Yes' for col in involvement_cols])\n",
    "        if yes_count > 1:\n",
    "            for col in involvement_cols:\n",
    "                row[col] = 'Unknown'\n",
    "    return row\n",
    "\n",
    "merged_df = merged_df.apply(fix_single_crash_vehicle_flags, axis=1)\n",
    "\n",
    "# Define the logic for heavy vehicles involvement\n",
    "# Define function for exact mapping\n",
    "def get_involvement_category(row):\n",
    "    bus = row['Bus Involvement']\n",
    "    rigid = row['Heavy Rigid Truck Involvement']\n",
    "    artic = row['Articulated Truck Involvement']\n",
    "    \n",
    "    # Check for fully unknown\n",
    "    if bus == 'Unknown' and rigid == 'Unknown' and artic == 'Unknown':\n",
    "        return 'Unknown'\n",
    "    \n",
    "    # Check all three are involved\n",
    "    if bus == 'Yes' and rigid == 'Yes' and artic == 'Yes':\n",
    "        return 'Bus, Articulated Truck and Heavy Rigid Truck Involved'\n",
    "    \n",
    "    # Pairwise checks\n",
    "    if bus == 'Yes' and artic == 'Yes' and rigid != 'Yes':\n",
    "        return 'Bus and Articulated Truck Involved as Known'\n",
    "    if bus == 'Yes' and rigid == 'Yes' and artic != 'Yes':\n",
    "        return 'Bus and Heavy Rigid Truck Involved as Known'\n",
    "    if artic == 'Yes' and rigid == 'Yes' and bus != 'Yes':\n",
    "        return 'Articulated Truck and Heavy Rigid Truck Involved as Known'\n",
    "    \n",
    "    # Single vehicle checks\n",
    "    if bus == 'Yes' and rigid != 'Yes' and artic != 'Yes':\n",
    "        return 'Only Bus Involved as Known'\n",
    "    if artic == 'Yes' and bus != 'Yes' and rigid != 'Yes':\n",
    "        return 'Only Articulated Truck Involved as Known'\n",
    "    if rigid == 'Yes' and bus != 'Yes' and artic != 'Yes':\n",
    "        return 'Only Heavy Rigid Truck Involved as Known'\n",
    "    \n",
    "    # All no\n",
    "    if bus == 'No' and rigid == 'No' and artic == 'No':\n",
    "        return 'No Heavy Vehicles Involved'\n",
    "\n",
    "    # Default\n",
    "    return 'Unknown'\n",
    "    \n",
    "merged_df['Vehicle Involvement'] = merged_df[\n",
    "    ['Bus Involvement', 'Heavy Rigid Truck Involvement', 'Articulated Truck Involvement']\n",
    "].apply(get_involvement_category, axis=1)\n",
    "\n",
    "\n",
    "# Additional Cleaning Rules\n",
    "\n",
    "# Make the State column all caps\n",
    "merged_df['State'] = merged_df['State'].str.upper()\n",
    "\n",
    "# Age: -9 and 0 → NaN\n",
    "merged_df['Age'] = pd.to_numeric(merged_df['Age'], errors='coerce')\n",
    "merged_df['Age'] = merged_df['Age'].replace({-9: np.nan, 0: np.nan})\n",
    "\n",
    "# Gender: -9 → 'Unknown'\n",
    "merged_df['Gender'] = merged_df['Gender'].replace(-9, 'Unknown')\n",
    "merged_df['Gender'] = merged_df['Gender'].apply(lambda x: 'Unknown' if str(x).strip().lower() == 'unknown' else x)\n",
    "\n",
    "# Time: blank → NaN\n",
    "merged_df['Time'] = merged_df['Time'].replace('', np.nan)\n",
    "\n",
    "# Road User: 'Other' and -9 → 'Others'\n",
    "merged_df['Road User'] = merged_df['Road User'].apply(\n",
    "    lambda x: 'Others' if str(x).strip().lower() == 'other/-9' else x\n",
    ")\n",
    "\n",
    "# Age Group: '0_to_16' → '1_to_16'; -9 → 'Unknown'\n",
    "merged_df['Age Group'] = merged_df['Age Group'].replace({'0_to_16': '1_to_16', -9: 'Unknown'})\n",
    "merged_df['Age Group'] = merged_df['Age Group'].apply(\n",
    "    lambda x: 'Unknown' if str(x).strip().lower() in ['-9', 'unknown', 'nan'] else x\n",
    ")\n",
    "\n",
    "# Derive 'Day of week' from 'Dayweek'\n",
    "merged_df['Dayweek'] = merged_df['Dayweek'].astype(str).str.strip().str.capitalize()\n",
    "merged_df['Day of week'] = merged_df['Dayweek'].apply(\n",
    "    lambda x: 'Weekend' if x in ['Saturday', 'Sunday'] else 'Weekday'\n",
    ")\n",
    "\n",
    "# Specifically convert 'Undetermined' to 'Unknown' in National Road Type\n",
    "merged_df['National Road Type'] = merged_df['National Road Type'].apply(\n",
    "    lambda x: 'Unknown' if str(x).strip().lower() == 'undetermined' else x\n",
    ")\n",
    "\n",
    "# Fix SA4 Name when LGA is Clarence and SA4 is Unknown\n",
    "merged_df.loc[\n",
    "    (merged_df['National LGA Name 2021'].str.strip().str.lower() == 'clarence') &\n",
    "    (merged_df['SA4 Name 2021'].str.strip().str.lower() == 'unknown'),\n",
    "    'SA4 Name 2021'\n",
    "] = 'Hobart'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d400605c-c5e8-47ef-b2ab-10fecb57790c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Only convert strings to time, keep time objects as-is\n",
    "merged_df['Time'] = merged_df['Time'].apply(\n",
    "    lambda x: datetime.strptime(x, '%H:%M:%S').time() if isinstance(x, str) else x\n",
    ")\n",
    "\n",
    "# Define time-of-day logic\n",
    "def get_time_of_day(t):\n",
    "    if pd.isna(t):\n",
    "        return 'Unknown'\n",
    "    elif t.hour >= 6 and t.hour < 18:\n",
    "        return 'Day'\n",
    "    else:\n",
    "        return 'Night'\n",
    "\n",
    "# Apply the function\n",
    "merged_df['Time of day'] = merged_df['Time'].apply(get_time_of_day)\n",
    "\n",
    "# Create a Holiday Indicator column. \n",
    "def assign_holiday(row):\n",
    "    if row['Christmas Period'] == 'Yes':\n",
    "        return 'Christmas'\n",
    "    elif row['Easter Period'] == 'Yes':\n",
    "        return 'Easter'\n",
    "    else:\n",
    "        return 'Non-Holiday'\n",
    "\n",
    "merged_df['Holiday Indicator'] = merged_df.apply(assign_holiday, axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2557595b-01ce-4c73-bc57-026029ceb79b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing ages before imputation: 232\n",
      "Mode of Age in '1_to_16' group: 16.0\n",
      "Missing ages after imputation: 0\n",
      "Total rows filled with mode: 232\n"
     ]
    }
   ],
   "source": [
    "# Fix Age Group for rows where Age = 19 and Age Group is Unknown\n",
    "merged_df.loc[\n",
    "    (merged_df['Age'] == 19) & (merged_df['Age Group'].str.lower() == 'unknown'),\n",
    "    'Age Group'\n",
    "] = '17_to_25'\n",
    "\n",
    "# Fix Age where the Age Group is known (1_to_16)\n",
    "missing_before = merged_df[\n",
    "    (merged_df['Age Group'] == '1_to_16') & (merged_df['Age'].isna())\n",
    "].shape[0]\n",
    "\n",
    "print(f\"Missing ages before imputation: {missing_before}\")\n",
    "\n",
    "# Make sure Age is numeric\n",
    "merged_df['Age'] = pd.to_numeric(merged_df['Age'], errors='coerce')\n",
    "\n",
    "# Filter for rows where Age Group is 1_to_16 and Age is NOT null\n",
    "ages_in_group = merged_df.loc[\n",
    "    (merged_df['Age Group'] == '1_to_16') & (merged_df['Age'].notna()),\n",
    "    'Age'\n",
    "]\n",
    "\n",
    "# Calculate mode\n",
    "age_mode_1_to_16 = ages_in_group.mode().iloc[0]  # Take first mode if multiple\n",
    "print(f\"Mode of Age in '1_to_16' group: {age_mode_1_to_16}\")\n",
    "\n",
    "# Fill missing Age values in this group with the mode\n",
    "merged_df.loc[\n",
    "    (merged_df['Age Group'] == '1_to_16') & (merged_df['Age'].isna()),\n",
    "    'Age'\n",
    "] = age_mode_1_to_16\n",
    "\n",
    "missing_after = merged_df[\n",
    "    (merged_df['Age Group'] == '1_to_16') & (merged_df['Age'].isna())\n",
    "].shape[0]\n",
    "\n",
    "print(f\"Missing ages after imputation: {missing_after}\")\n",
    "\n",
    "rows_filled = missing_before - missing_after\n",
    "print(f\"Total rows filled with mode: {rows_filled}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "64846066-e39a-42f5-9cb5-6eddaac41309",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Aparna\\AppData\\Local\\Temp\\ipykernel_21272\\143186521.py:15: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  merged_df[columns_to_check].applymap(is_unknown_or_blank).all(axis=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total rows where all 5 columns are unknown/blank/NaN: 1401\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Aparna\\AppData\\Local\\Temp\\ipykernel_21272\\143186521.py:25: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  mask = merged_df[columns_to_check].applymap(is_unknown_or_blank).all(axis=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total rows before cleaning: 56874\n",
      "Rows removed: 1401\n",
      "Percentage removed: 2.46%\n",
      "Remaining rows: 55473\n"
     ]
    }
   ],
   "source": [
    "columns_to_check = [\n",
    "    'Speed Limit',\n",
    "    'National Remoteness Areas',\n",
    "    'SA4 Name 2021',\n",
    "    'National LGA Name 2021',\n",
    "    'National Road Type'\n",
    "]\n",
    "\n",
    "# Define helper function to check \"unknown\" status\n",
    "def is_unknown_or_blank(val):\n",
    "    return pd.isna(val) or val == '' or str(val).strip().lower() == 'unknown' or str(val).strip().lower() == 'undetermined'\n",
    "\n",
    "# Apply the function across all specified columns\n",
    "filtered_rows = merged_df[\n",
    "    merged_df[columns_to_check].applymap(is_unknown_or_blank).all(axis=1)\n",
    "]\n",
    "\n",
    "# Show how many such rows exist\n",
    "print(f\"Total rows where all 5 columns are unknown/blank/NaN: {len(filtered_rows)}\")\n",
    "\n",
    "# Original number of rows\n",
    "total_rows = len(merged_df)\n",
    "\n",
    "# Boolean mask for rows to remove\n",
    "mask = merged_df[columns_to_check].applymap(is_unknown_or_blank).all(axis=1)\n",
    "\n",
    "# Count rows to be removed\n",
    "rows_to_remove = mask.sum()\n",
    "\n",
    "# Calculate percentage removed\n",
    "percent_removed = (rows_to_remove / total_rows) * 100\n",
    "\n",
    "# Remove rows\n",
    "merged_df_cleaned = merged_df[~mask]\n",
    "\n",
    "# Print log\n",
    "print(f\"Total rows before cleaning: {total_rows}\")\n",
    "print(f\"Rows removed: {rows_to_remove}\")\n",
    "print(f\"Percentage removed: {percent_removed:.2f}%\")\n",
    "print(f\"Remaining rows: {len(merged_df_cleaned)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5a89867a-5165-4887-92ac-c5383a9f9ca3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Crash ID State  Month  Year Dayweek      Time Crash Type Bus Involvement  \\\n",
      "0  20241115   NSW     12  2024  Friday  04:00:00     Single              No   \n",
      "1  20241125   NSW     12  2024  Friday  06:15:00     Single              No   \n",
      "2  20246013   TAS     12  2024  Friday  09:43:00   Multiple              No   \n",
      "3  20241002   NSW     12  2024  Friday  10:35:00   Multiple              No   \n",
      "5  20243185   QLD     12  2024  Friday  13:00:00   Multiple              No   \n",
      "\n",
      "  Heavy Rigid Truck Involvement Articulated Truck Involvement  ...  \\\n",
      "0                            No                            No  ...   \n",
      "1                            No                            No  ...   \n",
      "2                            No                            No  ...   \n",
      "3                            No                            No  ...   \n",
      "5                            No                            No  ...   \n",
      "\n",
      "  National LGA Name 2021         National Road Type Christmas Period  \\\n",
      "0            Wagga Wagga              Arterial Road              Yes   \n",
      "1             Hawkesbury                 Local Road               No   \n",
      "2      Northern Midlands                 Local Road              Yes   \n",
      "3      Armidale Regional  National or State Highway               No   \n",
      "5         Lockyer Valley  National or State Highway               No   \n",
      "\n",
      "   Easter Period Age Group Day of week Time of day Number Fatalities  \\\n",
      "0             No  65_to_74     Weekday       Night                 1   \n",
      "1             No  17_to_25     Weekday         Day                 1   \n",
      "2             No  26_to_39     Weekday         Day                 1   \n",
      "3             No  26_to_39     Weekday         Day                 1   \n",
      "5             No  40_to_64     Weekday         Day                 1   \n",
      "\n",
      "          Vehicle Involvement Holiday Indicator  \n",
      "0  No Heavy Vehicles Involved         Christmas  \n",
      "1  No Heavy Vehicles Involved       Non-Holiday  \n",
      "2  No Heavy Vehicles Involved         Christmas  \n",
      "3  No Heavy Vehicles Involved       Non-Holiday  \n",
      "5  No Heavy Vehicles Involved       Non-Holiday  \n",
      "\n",
      "[5 rows x 26 columns]\n"
     ]
    }
   ],
   "source": [
    "# Preview the merged DataFrame\n",
    "print(merged_df_cleaned.head())\n",
    "\n",
    "# Save to a new Excel\n",
    "merged_df_cleaned.to_csv('merged_fatalities_crashes.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b87c99e-acab-47af-b7d0-27a1a39f73dc",
   "metadata": {},
   "source": [
    "## Road User"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3041a4ea-f907-4b5c-9609-4b843633f06a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Extract unique road user categories\n",
    "dim_road_user = merged_df[['Road User']].drop_duplicates().reset_index(drop=True)\n",
    "\n",
    "# Step 2: Generate road_user_id like RU1, RU2...\n",
    "dim_road_user['road_user_id'] = ['RU' + str(i+1) for i in range(len(dim_road_user))]\n",
    "\n",
    "# Step 3: Reorder columns\n",
    "dim_road_user = dim_road_user[['road_user_id', 'Road User']]\n",
    "\n",
    "dim_road_user.to_csv(\"dim_road_user.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef36fd78-8c83-4512-ab6f-e9ea964d46ce",
   "metadata": {},
   "source": [
    "## National Road Type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "637f7f4b-e378-4469-b03d-eeeef490dbc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Extract unique road types from the cleaned dataset\n",
    "dim_national_road_type = merged_df_cleaned[['National Road Type']].drop_duplicates().reset_index(drop=True)\n",
    "\n",
    "# Step 2: Create surrogate keys like NR1, NR2, ...\n",
    "dim_national_road_type['national_road_type_id'] = ['NR' + str(i+1) for i in range(len(dim_national_road_type))]\n",
    "\n",
    "# Step 3: Reorder columns\n",
    "dim_national_road_type = dim_national_road_type[['national_road_type_id', 'National Road Type']]\n",
    "\n",
    "dim_national_road_type.to_csv(\"dim_national_road_type.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68465b7e-859d-4099-8143-8252ee3f1984",
   "metadata": {},
   "source": [
    "## Crash Type Dimesnion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bb826e28-c337-4821-9f04-ca7ed0afd9fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Extract unique crash types from the cleaned dataset\n",
    "dim_crash_type = merged_df_cleaned[['Crash Type']].drop_duplicates().reset_index(drop=True)\n",
    "\n",
    "# Step 2: Create surrogate keys like CT1, CT2, ...\n",
    "dim_crash_type['crash_type_id'] = ['CT' + str(i+1) for i in range(len(dim_crash_type))]\n",
    "\n",
    "# Step 3: Reorder columns\n",
    "dim_crash_type = dim_crash_type[['crash_type_id', 'Crash Type']]\n",
    "\n",
    "dim_crash_type.to_csv(\"dim_crash_type.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1790953-087c-407c-a2fc-a76deed6537c",
   "metadata": {},
   "source": [
    "## Vehicle involvement Dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1f3bbae7-70e2-45e9-b416-3a41ddd9592b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dim_vehicle = merged_df_cleaned[[\n",
    "    'Bus Involvement',\n",
    "    'Heavy Rigid Truck Involvement',\n",
    "    'Articulated Truck Involvement',\n",
    "    'Vehicle Involvement'\n",
    "]].drop_duplicates().reset_index(drop=True)\n",
    "\n",
    "# Add surrogate key\n",
    "dim_vehicle['vehicle_involvement_id'] = ['VI' + str(i+1) for i in range(len(dim_vehicle))]\n",
    "\n",
    "# Reorder columns\n",
    "dim_vehicle = dim_vehicle[[\n",
    "    'vehicle_involvement_id',\n",
    "    'Bus Involvement',\n",
    "    'Heavy Rigid Truck Involvement',\n",
    "    'Articulated Truck Involvement',\n",
    "    'Vehicle Involvement'\n",
    "]]\n",
    "\n",
    "# Save to CSV\n",
    "dim_vehicle.to_csv(\"dim_vehicle_involvement.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53716c14-a022-492f-a22b-c354ddcc7ed6",
   "metadata": {},
   "source": [
    "# Person Dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4bb32432-e443-4d22-9643-3fd862e2c6b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Select relevant columns from the cleaned fact table\n",
    "dim_person = merged_df_cleaned[[\n",
    "    'Gender',\n",
    "    'Age',\n",
    "    'Age Group'\n",
    "]].drop_duplicates().reset_index(drop=True)\n",
    "\n",
    "# Step 2: Create surrogate keys like P1, P2, ...\n",
    "dim_person['person_id'] = ['P' + str(i+1) for i in range(len(dim_person))]\n",
    "\n",
    "# Step 3: Reorder columns\n",
    "dim_person = dim_person[[\n",
    "    'person_id',\n",
    "    'Gender',\n",
    "    'Age',\n",
    "    'Age Group'\n",
    "]]\n",
    "\n",
    "dim_person.to_csv(\"dim_person.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b66668a2-83e9-49cf-a199-8e1f249f2f3c",
   "metadata": {},
   "source": [
    "## Date Dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "38f0b035-6890-4bf7-b0ef-6e3261f4c872",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Extract relevant columns\n",
    "dim_date = merged_df_cleaned[[\n",
    "    'Year', 'Month', 'Dayweek', 'Day of week', 'Holiday Indicator'\n",
    "]].drop_duplicates().reset_index(drop=True)\n",
    "\n",
    "\n",
    "# Step 3: Generate surrogate keys like D1, D2, D3...\n",
    "dim_date['date_id'] = ['D' + str(i+1) for i in range(len(dim_date))]\n",
    "\n",
    "# Step 4: Reorder columns\n",
    "dim_date = dim_date[[\n",
    "    'date_id', 'Year', 'Month', 'Dayweek', 'Day of week', 'Holiday Indicator'\n",
    "]]\n",
    "\n",
    "# Step 5: Save to CSV\n",
    "dim_date.to_csv(\"dim_date.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11bcd6a1-aad0-499c-b0b6-98701d50ab27",
   "metadata": {},
   "source": [
    "## LGA Dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f650785a-df2f-41ce-9570-d40fff6a13a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "dim_lga = pd.read_csv(\"LGA (count of dwellings).csv\")\n",
    "\n",
    "# Add surrogate key column\n",
    "dim_lga['lga_id'] = ['LGA' + str(i + 1) for i in range(len(dim_lga))]\n",
    "\n",
    "# Reorder columns to put lga_id first\n",
    "dim_lga = dim_lga[['lga_id'] + [col for col in dim_lga.columns if col != 'lga_id']]\n",
    "\n",
    "# Add Unknown row\n",
    "unknown_row = pd.DataFrame({\n",
    "    'lga_id': ['LGA0'],\n",
    "    'LGA': ['Unknown'],\n",
    "    'Dwellings Count': [0]\n",
    "})\n",
    "\n",
    "# Append and remove duplicates just in case\n",
    "dim_lga = pd.concat([unknown_row, dim_lga], ignore_index=True).drop_duplicates()\n",
    "\n",
    "# Save to CSV\n",
    "dim_lga.to_csv(\"dim_lga.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76bdd231-6609-4ae1-a849-96d3e6d8e3aa",
   "metadata": {},
   "source": [
    "## Location Dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4944babd-865a-4a96-a422-039ba0110c53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dim_lga\n",
    "dim_lga = pd.read_csv('dim_lga.csv')\n",
    "\n",
    "# Step 1: Prepare dim_location base table\n",
    "dim_location = merged_df_cleaned[[\n",
    "    'National LGA Name 2021',\n",
    "    'National Remoteness Areas',\n",
    "    'SA4 Name 2021',\n",
    "    'State'\n",
    "]].drop_duplicates().reset_index(drop=True)\n",
    "\n",
    "# Step 2: Strip 'Shire' and leading/trailing spaces for cleaner matching\n",
    "dim_location['Cleaned LGA'] = dim_location['National LGA Name 2021'].str.replace('Shire', '', regex=False).str.strip()\n",
    "dim_lga['Cleaned LGA'] = dim_lga['LGA'].str.replace('Shire', '', regex=False).str.strip()\n",
    "\n",
    "# Step 3: Handle special mapping logic\n",
    "def resolve_lga_name(row):\n",
    "    name = row['Cleaned LGA']\n",
    "    state = row['State']\n",
    "\n",
    "    if name == 'Cootamundra-Gundagai':\n",
    "        return 'Cootamundra-Gundagai Regional'\n",
    "    elif name == 'Nambucca':\n",
    "        return 'Nambucca Valley'\n",
    "    elif name == 'Campbelltown':\n",
    "        return 'Campbelltown (NSW)' if state == 'NSW' else 'Campbelltown (SA)'\n",
    "    elif name == 'Unincorporated':\n",
    "        return f'Unincorporated {state}'\n",
    "    elif name == 'Bayside':\n",
    "        return f'Bayside ({state})'\n",
    "    elif name == 'Central Coast':\n",
    "        return f'Central Coast ({state})'\n",
    "    else:\n",
    "        return name\n",
    "\n",
    "dim_location['Resolved LGA Name'] = dim_location.apply(resolve_lga_name, axis=1)\n",
    "\n",
    "# Step 4: Merge with dim_lga on Resolved Name\n",
    "dim_location = dim_location.merge(\n",
    "    dim_lga[['lga_id', 'LGA', 'Cleaned LGA']],\n",
    "    left_on='Resolved LGA Name',\n",
    "    right_on='Cleaned LGA',\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "# Step 5: Assign location_id\n",
    "dim_location['location_id'] = ['L' + str(i + 1) for i in range(len(dim_location))]\n",
    "\n",
    "# Step 6: Final cleanup\n",
    "dim_location = dim_location[[\n",
    "    'location_id', 'lga_id', 'State', 'National Remoteness Areas',\n",
    "    'SA4 Name 2021', 'National LGA Name 2021'\n",
    "]]\n",
    "\n",
    "# Save to CSV\n",
    "dim_location.to_csv('dim_location.csv', index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f33ae652-45fe-4e9e-8e61-a1070cafc1f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>national_road_type_id</th>\n",
       "      <th>National Road Type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NR1</td>\n",
       "      <td>Arterial Road</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NR2</td>\n",
       "      <td>Local Road</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NR3</td>\n",
       "      <td>National or State Highway</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NR4</td>\n",
       "      <td>Sub-arterial Road</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NR5</td>\n",
       "      <td>Unknown</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  national_road_type_id         National Road Type\n",
       "0                   NR1              Arterial Road\n",
       "1                   NR2                 Local Road\n",
       "2                   NR3  National or State Highway\n",
       "3                   NR4          Sub-arterial Road\n",
       "4                   NR5                    Unknown"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dim_national_road_type.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3ae184b9-d1df-42e8-9230-7c3b7a91ef7e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>location_id</th>\n",
       "      <th>lga_id</th>\n",
       "      <th>State</th>\n",
       "      <th>National Remoteness Areas</th>\n",
       "      <th>SA4 Name 2021</th>\n",
       "      <th>National LGA Name 2021</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>L1</td>\n",
       "      <td>LGA115</td>\n",
       "      <td>NSW</td>\n",
       "      <td>Inner Regional Australia</td>\n",
       "      <td>Riverina</td>\n",
       "      <td>Wagga Wagga</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>L2</td>\n",
       "      <td>LGA52</td>\n",
       "      <td>NSW</td>\n",
       "      <td>Inner Regional Australia</td>\n",
       "      <td>Sydney - Baulkham Hills and Hawkesbury</td>\n",
       "      <td>Hawkesbury</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>L3</td>\n",
       "      <td>LGA525</td>\n",
       "      <td>TAS</td>\n",
       "      <td>Inner Regional Australia</td>\n",
       "      <td>Launceston and North East</td>\n",
       "      <td>Northern Midlands</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>L4</td>\n",
       "      <td>LGA2</td>\n",
       "      <td>NSW</td>\n",
       "      <td>Outer Regional Australia</td>\n",
       "      <td>New England and North West</td>\n",
       "      <td>Armidale Regional</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>L5</td>\n",
       "      <td>LGA250</td>\n",
       "      <td>QLD</td>\n",
       "      <td>Inner Regional Australia</td>\n",
       "      <td>Toowoomba</td>\n",
       "      <td>Lockyer Valley</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  location_id  lga_id State National Remoteness Areas  \\\n",
       "0          L1  LGA115   NSW  Inner Regional Australia   \n",
       "1          L2   LGA52   NSW  Inner Regional Australia   \n",
       "2          L3  LGA525   TAS  Inner Regional Australia   \n",
       "3          L4    LGA2   NSW  Outer Regional Australia   \n",
       "4          L5  LGA250   QLD  Inner Regional Australia   \n",
       "\n",
       "                            SA4 Name 2021 National LGA Name 2021  \n",
       "0                                Riverina            Wagga Wagga  \n",
       "1  Sydney - Baulkham Hills and Hawkesbury             Hawkesbury  \n",
       "2               Launceston and North East      Northern Midlands  \n",
       "3              New England and North West      Armidale Regional  \n",
       "4                               Toowoomba         Lockyer Valley  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dim_location.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cec0a33b-b3a2-4d2c-a03e-05eca3fa12a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lga_id</th>\n",
       "      <th>LGA</th>\n",
       "      <th>Dwellings Count</th>\n",
       "      <th>Cleaned LGA</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LGA0</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>0</td>\n",
       "      <td>Unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LGA1</td>\n",
       "      <td>Albury</td>\n",
       "      <td>25430</td>\n",
       "      <td>Albury</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LGA2</td>\n",
       "      <td>Armidale Regional</td>\n",
       "      <td>12955</td>\n",
       "      <td>Armidale Regional</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LGA3</td>\n",
       "      <td>Ballina</td>\n",
       "      <td>20889</td>\n",
       "      <td>Ballina</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LGA4</td>\n",
       "      <td>Balranald</td>\n",
       "      <td>1091</td>\n",
       "      <td>Balranald</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  lga_id                LGA  Dwellings Count        Cleaned LGA\n",
       "0   LGA0            Unknown                0            Unknown\n",
       "1   LGA1             Albury            25430             Albury\n",
       "2   LGA2  Armidale Regional            12955  Armidale Regional\n",
       "3   LGA3            Ballina            20889            Ballina\n",
       "4   LGA4          Balranald             1091          Balranald"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dim_lga.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e9d93463-f024-42b2-a745-c0850eb560de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date_id</th>\n",
       "      <th>Year</th>\n",
       "      <th>Month</th>\n",
       "      <th>Dayweek</th>\n",
       "      <th>Day of week</th>\n",
       "      <th>Holiday Indicator</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>D1</td>\n",
       "      <td>2024</td>\n",
       "      <td>12</td>\n",
       "      <td>Friday</td>\n",
       "      <td>Weekday</td>\n",
       "      <td>Christmas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>D2</td>\n",
       "      <td>2024</td>\n",
       "      <td>12</td>\n",
       "      <td>Friday</td>\n",
       "      <td>Weekday</td>\n",
       "      <td>Non-Holiday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>D3</td>\n",
       "      <td>2024</td>\n",
       "      <td>12</td>\n",
       "      <td>Monday</td>\n",
       "      <td>Weekday</td>\n",
       "      <td>Non-Holiday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>D4</td>\n",
       "      <td>2024</td>\n",
       "      <td>12</td>\n",
       "      <td>Monday</td>\n",
       "      <td>Weekday</td>\n",
       "      <td>Christmas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>D5</td>\n",
       "      <td>2024</td>\n",
       "      <td>12</td>\n",
       "      <td>Saturday</td>\n",
       "      <td>Weekend</td>\n",
       "      <td>Non-Holiday</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  date_id  Year  Month   Dayweek Day of week Holiday Indicator\n",
       "0      D1  2024     12    Friday     Weekday         Christmas\n",
       "1      D2  2024     12    Friday     Weekday       Non-Holiday\n",
       "2      D3  2024     12    Monday     Weekday       Non-Holiday\n",
       "3      D4  2024     12    Monday     Weekday         Christmas\n",
       "4      D5  2024     12  Saturday     Weekend       Non-Holiday"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dim_date.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7ddb917a-af6e-439c-a394-bb66bf6779bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>vehicle_involvement_id</th>\n",
       "      <th>Bus Involvement</th>\n",
       "      <th>Heavy Rigid Truck Involvement</th>\n",
       "      <th>Articulated Truck Involvement</th>\n",
       "      <th>Vehicle Involvement</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>VI1</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No Heavy Vehicles Involved</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>VI2</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Only Articulated Truck Involved as Known</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>VI3</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>VI4</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Bus and Articulated Truck Involved as Known</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>VI5</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>Only Heavy Rigid Truck Involved as Known</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  vehicle_involvement_id Bus Involvement Heavy Rigid Truck Involvement  \\\n",
       "0                    VI1              No                            No   \n",
       "1                    VI2              No                            No   \n",
       "2                    VI3         Unknown                       Unknown   \n",
       "3                    VI4             Yes                            No   \n",
       "4                    VI5              No                           Yes   \n",
       "\n",
       "  Articulated Truck Involvement                          Vehicle Involvement  \n",
       "0                            No                   No Heavy Vehicles Involved  \n",
       "1                           Yes     Only Articulated Truck Involved as Known  \n",
       "2                       Unknown                                      Unknown  \n",
       "3                           Yes  Bus and Articulated Truck Involved as Known  \n",
       "4                            No     Only Heavy Rigid Truck Involved as Known  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dim_vehicle.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e3736c35-41bf-46af-8271-27a343b19c6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>person_id</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Age Group</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>P1</td>\n",
       "      <td>Male</td>\n",
       "      <td>74.0</td>\n",
       "      <td>65_to_74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>P2</td>\n",
       "      <td>Female</td>\n",
       "      <td>19.0</td>\n",
       "      <td>17_to_25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>P3</td>\n",
       "      <td>Female</td>\n",
       "      <td>33.0</td>\n",
       "      <td>26_to_39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>P4</td>\n",
       "      <td>Female</td>\n",
       "      <td>32.0</td>\n",
       "      <td>26_to_39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>P5</td>\n",
       "      <td>Female</td>\n",
       "      <td>61.0</td>\n",
       "      <td>40_to_64</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  person_id  Gender   Age Age Group\n",
       "0        P1    Male  74.0  65_to_74\n",
       "1        P2  Female  19.0  17_to_25\n",
       "2        P3  Female  33.0  26_to_39\n",
       "3        P4  Female  32.0  26_to_39\n",
       "4        P5  Female  61.0  40_to_64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dim_person.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d90cd6b0-bfe0-47a7-8394-6e0f49322e60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>road_user_id</th>\n",
       "      <th>Road User</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RU1</td>\n",
       "      <td>Driver</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RU2</td>\n",
       "      <td>Passenger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RU3</td>\n",
       "      <td>Motorcycle rider</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RU4</td>\n",
       "      <td>Pedestrian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RU5</td>\n",
       "      <td>Pedal cyclist</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  road_user_id         Road User\n",
       "0          RU1            Driver\n",
       "1          RU2         Passenger\n",
       "2          RU3  Motorcycle rider\n",
       "3          RU4        Pedestrian\n",
       "4          RU5     Pedal cyclist"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dim_road_user.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d8f31be9-99d4-4422-b09f-759353bd251f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>crash_type_id</th>\n",
       "      <th>Crash Type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CT1</td>\n",
       "      <td>Single</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CT2</td>\n",
       "      <td>Multiple</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  crash_type_id Crash Type\n",
       "0           CT1     Single\n",
       "1           CT2   Multiple"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dim_crash_type.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8dfd3696-6643-4091-9637-31dde02fa42d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load main data\n",
    "merged_df_cleaned = pd.read_csv(\"merged_fatalities_crashes.csv\")\n",
    "\n",
    "# Load dimension tables\n",
    "dim_date = pd.read_csv(\"dim_date.csv\")\n",
    "dim_location = pd.read_csv(\"dim_location.csv\")\n",
    "dim_crash_type = pd.read_csv(\"dim_crash_type.csv\")\n",
    "dim_person = pd.read_csv(\"dim_person.csv\")\n",
    "dim_road_user = pd.read_csv(\"dim_road_user.csv\")\n",
    "dim_vehicle = pd.read_csv(\"dim_vehicle_involvement.csv\")\n",
    "dim_road_type = pd.read_csv(\"dim_national_road_type.csv\")\n",
    "\n",
    "# Make a copy to start joining\n",
    "fact_df = merged_df_cleaned.copy()\n",
    "\n",
    "# --- Join with dimension tables to get IDs ---\n",
    "fact_df = fact_df.merge(\n",
    "    dim_date,\n",
    "    on=['Year', 'Month', 'Dayweek', 'Day of week', 'Holiday Indicator'],\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "fact_df = fact_df.merge(\n",
    "    dim_location,\n",
    "    on=['State', 'National Remoteness Areas', 'SA4 Name 2021', 'National LGA Name 2021'],\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "fact_df = fact_df.merge(\n",
    "    dim_crash_type,\n",
    "    on='Crash Type',\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "fact_df = fact_df.merge(\n",
    "    dim_person,\n",
    "    on=['Gender', 'Age', 'Age Group'],\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "fact_df = fact_df.merge(\n",
    "    dim_road_user,\n",
    "    left_on='Road User',\n",
    "    right_on='Road User',\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "fact_df = fact_df.merge(\n",
    "    dim_vehicle,\n",
    "    on=['Bus Involvement', 'Heavy Rigid Truck Involvement', 'Articulated Truck Involvement', 'Vehicle Involvement'],\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "fact_df = fact_df.merge(\n",
    "    dim_road_type,\n",
    "    on='National Road Type',\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "# Select relevant columns for the fact table\n",
    "fact_crash_df = fact_df[[\n",
    "    'Crash ID',\n",
    "    'date_id',\n",
    "    'location_id',\n",
    "    'road_user_id',\n",
    "    'person_id',\n",
    "    'crash_type_id',\n",
    "    'vehicle_involvement_id',\n",
    "    'national_road_type_id',\n",
    "    'Time',              # new\n",
    "    'Time of day',       # new\n",
    "    'Speed Limit',       # new\n",
    "    'Number Fatalities'\n",
    "]]\n",
    "\n",
    "# Rename columns to match DB schema\n",
    "fact_crash_df = fact_crash_df.rename(columns={\n",
    "    'Crash ID': 'crash_id',\n",
    "    'Time': 'time',\n",
    "    'Time of day': 'time_of_day',\n",
    "    'Speed Limit': 'speed_limit',\n",
    "    'Number Fatalities': 'number_fatalities'\n",
    "})\n",
    "\n",
    "# Save to CSV (no index)\n",
    "fact_crash_df.to_csv('fact_crash_fatalities.csv', index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "28cce595-0e5c-424e-86b0-85786755b3dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>crash_id</th>\n",
       "      <th>date_id</th>\n",
       "      <th>location_id</th>\n",
       "      <th>road_user_id</th>\n",
       "      <th>person_id</th>\n",
       "      <th>crash_type_id</th>\n",
       "      <th>vehicle_involvement_id</th>\n",
       "      <th>national_road_type_id</th>\n",
       "      <th>time</th>\n",
       "      <th>time_of_day</th>\n",
       "      <th>speed_limit</th>\n",
       "      <th>number_fatalities</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20241115</td>\n",
       "      <td>D1</td>\n",
       "      <td>L1</td>\n",
       "      <td>RU1</td>\n",
       "      <td>P1</td>\n",
       "      <td>CT1</td>\n",
       "      <td>VI1</td>\n",
       "      <td>NR1</td>\n",
       "      <td>04:00:00</td>\n",
       "      <td>Night</td>\n",
       "      <td>100.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20241125</td>\n",
       "      <td>D2</td>\n",
       "      <td>L2</td>\n",
       "      <td>RU1</td>\n",
       "      <td>P2</td>\n",
       "      <td>CT1</td>\n",
       "      <td>VI1</td>\n",
       "      <td>NR2</td>\n",
       "      <td>06:15:00</td>\n",
       "      <td>Day</td>\n",
       "      <td>80.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20246013</td>\n",
       "      <td>D1</td>\n",
       "      <td>L3</td>\n",
       "      <td>RU1</td>\n",
       "      <td>P3</td>\n",
       "      <td>CT2</td>\n",
       "      <td>VI1</td>\n",
       "      <td>NR2</td>\n",
       "      <td>09:43:00</td>\n",
       "      <td>Day</td>\n",
       "      <td>50.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20241002</td>\n",
       "      <td>D2</td>\n",
       "      <td>L4</td>\n",
       "      <td>RU1</td>\n",
       "      <td>P4</td>\n",
       "      <td>CT2</td>\n",
       "      <td>VI1</td>\n",
       "      <td>NR3</td>\n",
       "      <td>10:35:00</td>\n",
       "      <td>Day</td>\n",
       "      <td>100.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20243185</td>\n",
       "      <td>D2</td>\n",
       "      <td>L5</td>\n",
       "      <td>RU2</td>\n",
       "      <td>P5</td>\n",
       "      <td>CT2</td>\n",
       "      <td>VI1</td>\n",
       "      <td>NR3</td>\n",
       "      <td>13:00:00</td>\n",
       "      <td>Day</td>\n",
       "      <td>100.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   crash_id date_id location_id road_user_id person_id crash_type_id  \\\n",
       "0  20241115      D1          L1          RU1        P1           CT1   \n",
       "1  20241125      D2          L2          RU1        P2           CT1   \n",
       "2  20246013      D1          L3          RU1        P3           CT2   \n",
       "3  20241002      D2          L4          RU1        P4           CT2   \n",
       "4  20243185      D2          L5          RU2        P5           CT2   \n",
       "\n",
       "  vehicle_involvement_id national_road_type_id      time time_of_day  \\\n",
       "0                    VI1                   NR1  04:00:00       Night   \n",
       "1                    VI1                   NR2  06:15:00         Day   \n",
       "2                    VI1                   NR2  09:43:00         Day   \n",
       "3                    VI1                   NR3  10:35:00         Day   \n",
       "4                    VI1                   NR3  13:00:00         Day   \n",
       "\n",
       "   speed_limit  number_fatalities  \n",
       "0        100.0                  1  \n",
       "1         80.0                  1  \n",
       "2         50.0                  1  \n",
       "3        100.0                  1  \n",
       "4        100.0                  1  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fact_crash_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "34fb6e4b-84c1-42f9-8d24-2eb59b3b6db8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                          antecedents  \\\n",
      "8192                        (Male, Multiple, 1_to_16)   \n",
      "8199                                  (Pedal cyclist)   \n",
      "107716  (Day, Pedestrian, No Heavy Vehicles Involved)   \n",
      "107704                  (75_or_older, Single, Female)   \n",
      "142415  (Day, Pedestrian, No Heavy Vehicles Involved)   \n",
      "\n",
      "                                          consequents   support  confidence  \\\n",
      "8192                                  (Pedal cyclist)  0.005012    0.265521   \n",
      "8199                        (Male, Multiple, 1_to_16)  0.005012    0.183377   \n",
      "107716                  (75_or_older, Single, Female)  0.006022    0.159580   \n",
      "107704  (Day, Pedestrian, No Heavy Vehicles Involved)  0.006022    0.300090   \n",
      "142415     (Non-Holiday, 75_or_older, Single, Female)  0.005788    0.153368   \n",
      "\n",
      "            lift  \n",
      "8192    9.713918  \n",
      "8199    9.713918  \n",
      "107716  7.952023  \n",
      "107704  7.952023  \n",
      "142415  7.905313  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from mlxtend.frequent_patterns import apriori, association_rules\n",
    "from mlxtend.preprocessing import TransactionEncoder\n",
    "\n",
    "# Load your dataset\n",
    "df = pd.read_csv(\"merged_fatalities_crashes.csv\")\n",
    "\n",
    "# Select relevant categorical columns (keep it compact and relevant)\n",
    "cols = [\"Gender\", \"Age Group\", \"Time of day\", \"Day of week\", \"Crash Type\", \n",
    "    \"Vehicle Involvement\", \"Holiday Indicator\", \"Road User\"]\n",
    "\n",
    "# Drop rows with unknowns (optional: depends on your dataset's distribution)\n",
    "df = df[df['Road User'] != 'Unknown']\n",
    "\n",
    "# Convert to list of transactions\n",
    "transactions = df[cols].astype(str).values.tolist()\n",
    "\n",
    "# Transaction encoding\n",
    "te = TransactionEncoder()\n",
    "te_ary = te.fit(transactions).transform(transactions)\n",
    "df_encoded = pd.DataFrame(te_ary, columns=te.columns_)\n",
    "\n",
    "# Apply Apriori (very low threshold just to capture rules)\n",
    "frequent_itemsets = apriori(df_encoded, min_support=0.005, use_colnames=True)\n",
    "\n",
    "# Generate rules with very loose thresholds\n",
    "rules = association_rules(frequent_itemsets, metric=\"confidence\", min_threshold=0.1)\n",
    "\n",
    "\n",
    "rules_road_user = rules[rules['consequents'].apply(lambda x: any(item in ['Driver', 'Passenger', 'Pedestrian', 'Motorcycle rider', 'Pedal cyclist'] for item in x))]\n",
    "\n",
    "\n",
    "# Filter only rules with 'Road User=...' in the CONSEQUENT\n",
    "# rules = rules[rules['consequents'].astype(str).str.contains(\"Road User\")]\n",
    "\n",
    "# Sort by lift and confidence\n",
    "rules = rules.sort_values(by=[\"lift\", \"confidence\"], ascending=False)\n",
    "\n",
    "# Display top rules\n",
    "print(rules[['antecedents', 'consequents', 'support', 'confidence', 'lift']].head(5))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "84975e99-e1b1-4218-b08d-8e4e253d01de",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                           antecedents                                                                                                          consequents  support  confidence     lift\n",
      "                                   Gender=Male, Age Group=1_to_16, Crash Type=Multiple                                                                                              Road User=Pedal cyclist 0.005011    0.265267 9.706574\n",
      "                               Age Group=75_or_older, Gender=Female, Crash Type=Single                                Vehicle Involvement=No Heavy Vehicles Involved, Road User=Pedestrian, Time of day=Day 0.006021    0.300090 7.953600\n",
      "Crash Type=Single, Age Group=75_or_older, Gender=Female, Holiday Indicator=Non-Holiday                                Vehicle Involvement=No Heavy Vehicles Involved, Road User=Pedestrian, Time of day=Day 0.005787    0.298327 7.906881\n",
      "                               Age Group=75_or_older, Gender=Female, Crash Type=Single Vehicle Involvement=No Heavy Vehicles Involved, Road User=Pedestrian, Time of day=Day, Holiday Indicator=Non-Holiday 0.005787    0.288410 7.900717\n",
      "                                              Age Group=75_or_older, Crash Type=Single                 Vehicle Involvement=No Heavy Vehicles Involved, Time of day=Day, Road User=Pedestrian, Gender=Female 0.006021    0.117029 7.575186\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from mlxtend.frequent_patterns import apriori, association_rules\n",
    "from mlxtend.preprocessing import TransactionEncoder\n",
    "\n",
    "# Load your cleaned dataset\n",
    "df = pd.read_csv(\"merged_fatalities_crashes.csv\")\n",
    "\n",
    "# Filter to only relevant categorical columns\n",
    "cols = [\"Gender\", \"Age Group\", \"Time of day\", \"Day of week\", \"Crash Type\", \n",
    "        \"Vehicle Involvement\", \"Holiday Indicator\", \"Road User\"]\n",
    "\n",
    "df_subset = df[cols].astype(str)\n",
    "\n",
    "# Convert each row into a list of attribute=value for better readability\n",
    "transactions = df_subset.apply(lambda row: [f\"{col}={val}\" for col, val in row.items()], axis=1).tolist()\n",
    "\n",
    "# One-hot encode using TransactionEncoder\n",
    "te = TransactionEncoder()\n",
    "te_ary = te.fit(transactions).transform(transactions)\n",
    "df_encoded = pd.DataFrame(te_ary, columns=te.columns_)\n",
    "\n",
    "# Frequent Itemsets with low threshold for exploration\n",
    "frequent_itemsets = apriori(df_encoded, min_support=0.005, use_colnames=True)\n",
    "\n",
    "# Generate rules\n",
    "rules = association_rules(frequent_itemsets, metric=\"lift\", min_threshold=1.0)\n",
    "\n",
    "# Keep only rules where RHS has a Road User\n",
    "rules = rules[rules['consequents'].apply(lambda x: any(\"Road User=\" in item for item in x))]\n",
    "\n",
    "# Sort by confidence and lift\n",
    "rules_sorted = rules.sort_values(by=[\"lift\", \"confidence\"], ascending=False)\n",
    "\n",
    "# Make output prettier\n",
    "def format_set(s):\n",
    "    return ', '.join(list(s))\n",
    "\n",
    "rules_sorted[\"antecedents\"] = rules_sorted[\"antecedents\"].apply(format_set)\n",
    "rules_sorted[\"consequents\"] = rules_sorted[\"consequents\"].apply(format_set)\n",
    "\n",
    "# Show the top k rules (you can change k)\n",
    "k = 5\n",
    "pretty_rules = rules_sorted[[\"antecedents\", \"consequents\", \"support\", \"confidence\", \"lift\"]].head(k)\n",
    "\n",
    "# Display the result\n",
    "print(pretty_rules.to_string(index=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "fc142150-8a23-4a21-90a2-91e852f2fe83",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "</style>\n",
       "<table id=\"T_8409f\">\n",
       "  <caption>Top Association Rules with Road User as Consequent</caption>\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_8409f_level0_col0\" class=\"col_heading level0 col0\" >antecedents</th>\n",
       "      <th id=\"T_8409f_level0_col1\" class=\"col_heading level0 col1\" >consequents</th>\n",
       "      <th id=\"T_8409f_level0_col2\" class=\"col_heading level0 col2\" >support</th>\n",
       "      <th id=\"T_8409f_level0_col3\" class=\"col_heading level0 col3\" >confidence</th>\n",
       "      <th id=\"T_8409f_level0_col4\" class=\"col_heading level0 col4\" >lift</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_8409f_level0_row0\" class=\"row_heading level0 row0\" >75</th>\n",
       "      <td id=\"T_8409f_row0_col0\" class=\"data row0 col0\" >Gender=Female</td>\n",
       "      <td id=\"T_8409f_row0_col1\" class=\"data row0 col1\" >Road User=Passenger</td>\n",
       "      <td id=\"T_8409f_row0_col2\" class=\"data row0 col2\" >0.107000</td>\n",
       "      <td id=\"T_8409f_row0_col3\" class=\"data row0 col3\" >0.379000</td>\n",
       "      <td id=\"T_8409f_row0_col4\" class=\"data row0 col4\" >1.685000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_8409f_level0_row1\" class=\"row_heading level0 row1\" >527</th>\n",
       "      <td id=\"T_8409f_row1_col0\" class=\"data row1 col0\" >Gender=Female</td>\n",
       "      <td id=\"T_8409f_row1_col1\" class=\"data row1 col1\" >Holiday Indicator=Non-Holiday, Road User=Passenger</td>\n",
       "      <td id=\"T_8409f_row1_col2\" class=\"data row1 col2\" >0.102000</td>\n",
       "      <td id=\"T_8409f_row1_col3\" class=\"data row1 col3\" >0.361000</td>\n",
       "      <td id=\"T_8409f_row1_col4\" class=\"data row1 col4\" >1.681000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_8409f_level0_row2\" class=\"row_heading level0 row2\" >525</th>\n",
       "      <td id=\"T_8409f_row2_col0\" class=\"data row2 col0\" >Gender=Female, Holiday Indicator=Non-Holiday</td>\n",
       "      <td id=\"T_8409f_row2_col1\" class=\"data row2 col1\" >Road User=Passenger</td>\n",
       "      <td id=\"T_8409f_row2_col2\" class=\"data row2 col2\" >0.102000</td>\n",
       "      <td id=\"T_8409f_row2_col3\" class=\"data row2 col3\" >0.376000</td>\n",
       "      <td id=\"T_8409f_row2_col4\" class=\"data row2 col4\" >1.674000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_8409f_level0_row3\" class=\"row_heading level0 row3\" >385</th>\n",
       "      <td id=\"T_8409f_row3_col0\" class=\"data row3 col0\" >Crash Type=Single, Holiday Indicator=Non-Holiday</td>\n",
       "      <td id=\"T_8409f_row3_col1\" class=\"data row3 col1\" >Road User=Pedestrian</td>\n",
       "      <td id=\"T_8409f_row3_col2\" class=\"data row3 col2\" >0.130000</td>\n",
       "      <td id=\"T_8409f_row3_col3\" class=\"data row3 col3\" >0.245000</td>\n",
       "      <td id=\"T_8409f_row3_col4\" class=\"data row3 col4\" >1.593000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_8409f_level0_row4\" class=\"row_heading level0 row4\" >49</th>\n",
       "      <td id=\"T_8409f_row4_col0\" class=\"data row4 col0\" >Crash Type=Single</td>\n",
       "      <td id=\"T_8409f_row4_col1\" class=\"data row4 col1\" >Road User=Pedestrian</td>\n",
       "      <td id=\"T_8409f_row4_col2\" class=\"data row4 col2\" >0.134000</td>\n",
       "      <td id=\"T_8409f_row4_col3\" class=\"data row4 col3\" >0.243000</td>\n",
       "      <td id=\"T_8409f_row4_col4\" class=\"data row4 col4\" >1.581000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_8409f_level0_row5\" class=\"row_heading level0 row5\" >389</th>\n",
       "      <td id=\"T_8409f_row5_col0\" class=\"data row5 col0\" >Crash Type=Single</td>\n",
       "      <td id=\"T_8409f_row5_col1\" class=\"data row5 col1\" >Holiday Indicator=Non-Holiday, Road User=Pedestrian</td>\n",
       "      <td id=\"T_8409f_row5_col2\" class=\"data row5 col2\" >0.130000</td>\n",
       "      <td id=\"T_8409f_row5_col3\" class=\"data row5 col3\" >0.236000</td>\n",
       "      <td id=\"T_8409f_row5_col4\" class=\"data row5 col4\" >1.580000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_8409f_level0_row6\" class=\"row_heading level0 row6\" >1385</th>\n",
       "      <td id=\"T_8409f_row6_col0\" class=\"data row6 col0\" >Crash Type=Multiple, Day of week=Weekday</td>\n",
       "      <td id=\"T_8409f_row6_col1\" class=\"data row6 col1\" >Holiday Indicator=Non-Holiday, Road User=Driver, Time of day=Day</td>\n",
       "      <td id=\"T_8409f_row6_col2\" class=\"data row6 col2\" >0.111000</td>\n",
       "      <td id=\"T_8409f_row6_col3\" class=\"data row6 col3\" >0.352000</td>\n",
       "      <td id=\"T_8409f_row6_col4\" class=\"data row6 col4\" >1.410000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_8409f_level0_row7\" class=\"row_heading level0 row7\" >1371</th>\n",
       "      <td id=\"T_8409f_row7_col0\" class=\"data row7 col0\" >Crash Type=Multiple, Day of week=Weekday, Holiday Indicator=Non-Holiday</td>\n",
       "      <td id=\"T_8409f_row7_col1\" class=\"data row7 col1\" >Road User=Driver, Time of day=Day</td>\n",
       "      <td id=\"T_8409f_row7_col2\" class=\"data row7 col2\" >0.111000</td>\n",
       "      <td id=\"T_8409f_row7_col3\" class=\"data row7 col3\" >0.365000</td>\n",
       "      <td id=\"T_8409f_row7_col4\" class=\"data row7 col4\" >1.407000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_8409f_level0_row8\" class=\"row_heading level0 row8\" >784</th>\n",
       "      <td id=\"T_8409f_row8_col0\" class=\"data row8 col0\" >Crash Type=Multiple, Day of week=Weekday</td>\n",
       "      <td id=\"T_8409f_row8_col1\" class=\"data row8 col1\" >Road User=Driver, Time of day=Day</td>\n",
       "      <td id=\"T_8409f_row8_col2\" class=\"data row8 col2\" >0.115000</td>\n",
       "      <td id=\"T_8409f_row8_col3\" class=\"data row8 col3\" >0.364000</td>\n",
       "      <td id=\"T_8409f_row8_col4\" class=\"data row8 col4\" >1.405000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_8409f_level0_row9\" class=\"row_heading level0 row9\" >1461</th>\n",
       "      <td id=\"T_8409f_row9_col0\" class=\"data row9 col0\" >Gender=Male, Time of day=Night</td>\n",
       "      <td id=\"T_8409f_row9_col1\" class=\"data row9 col1\" >Crash Type=Single, Holiday Indicator=Non-Holiday, Road User=Driver</td>\n",
       "      <td id=\"T_8409f_row9_col2\" class=\"data row9 col2\" >0.105000</td>\n",
       "      <td id=\"T_8409f_row9_col3\" class=\"data row9 col3\" >0.314000</td>\n",
       "      <td id=\"T_8409f_row9_col4\" class=\"data row9 col4\" >1.375000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x1fb1de7b710>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from mlxtend.frequent_patterns import apriori, association_rules\n",
    "from mlxtend.preprocessing import TransactionEncoder\n",
    "\n",
    "# Load data\n",
    "df = pd.read_csv(\"merged_fatalities_crashes.csv\")\n",
    "\n",
    "# Select relevant categorical columns\n",
    "cols = [\"Gender\", \"Age Group\", \"Time of day\", \"Day of week\", \"Crash Type\", \n",
    "        \"Vehicle Involvement\", \"Holiday Indicator\", \"Road User\"]\n",
    "df_subset = df[cols].astype(str)\n",
    "\n",
    "# Convert rows into list of formatted strings like \"Gender=Male\"\n",
    "transactions = df_subset.apply(lambda row: [f\"{col}={val}\" for col, val in row.items()], axis=1).tolist()\n",
    "\n",
    "# One-hot encode\n",
    "te = TransactionEncoder()\n",
    "te_ary = te.fit_transform(transactions)\n",
    "df_encoded = pd.DataFrame(te_ary, columns=te.columns_)\n",
    "\n",
    "# Run Apriori\n",
    "frequent_itemsets = apriori(df_encoded, min_support=0.1, use_colnames=True)\n",
    "\n",
    "# Generate rules\n",
    "rules = association_rules(frequent_itemsets, metric=\"lift\", min_threshold=1.0)\n",
    "\n",
    "# Filter for Road User in RHS\n",
    "rules = rules[rules['consequents'].apply(lambda x: any(\"Road User=\" in item for item in x))]\n",
    "\n",
    "# Sort rules by lift and confidence\n",
    "rules_sorted = rules.sort_values(by=[\"lift\", \"confidence\"], ascending=False)\n",
    "\n",
    "# Format for pretty output\n",
    "rules_sorted[\"antecedents\"] = rules_sorted[\"antecedents\"].apply(lambda x: ', '.join(sorted(list(x))))\n",
    "rules_sorted[\"consequents\"] = rules_sorted[\"consequents\"].apply(lambda x: ', '.join(sorted(list(x))))\n",
    "rules_sorted[[\"support\", \"confidence\", \"lift\"]] = rules_sorted[[\"support\", \"confidence\", \"lift\"]].round(3)\n",
    "\n",
    "# Select final columns\n",
    "pretty_rules = rules_sorted[[\"antecedents\", \"consequents\", \"support\", \"confidence\", \"lift\"]].head(10)\n",
    "\n",
    "# Optional: export to CSV or styled HTML\n",
    "pretty_rules.to_csv(\"top_road_user_rules.csv\", index=False)\n",
    "\n",
    "# Display nicely in notebook\n",
    "from IPython.display import display\n",
    "display(pretty_rules.style.set_caption(\"Top Association Rules with Road User as Consequent\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b25f5ccd-6374-4096-8a77-ea73158f2f07",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "159d2ff8-747c-40c4-afc2-6f71a06639e8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
